{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dataset, ratio):\n",
    "    trainSize = int(len(dataset)*ratio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet)<trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return trainSet, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if vector[-1] not in separated:\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stddev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg, 2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stddev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summByClass(dataset):\n",
    "    separated = separate(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in  separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcProb(x, mean, stddev):\n",
    "    exponent = math.exp(-(math.pow(x-mean, 2)/(2*math.pow(stddev, 2))))\n",
    "    return (1/math.sqrt(2*math.pi)*stddev)*exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcClassProb(summaries, inputV):\n",
    "    probs = {}\n",
    "    for classValue, classSumm in summaries.items():\n",
    "        probs[classValue] = 1\n",
    "        for i in range(len(classSumm)):\n",
    "            mean, stddev = classSumm[i]\n",
    "            x = inputV[i]\n",
    "            probs[classValue] *= calcProb(x, mean, stddev)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, inputV):\n",
    "    probs = calcClassProb(summaries, inputV)\n",
    "    bestLabel, bestPeob = None, -1\n",
    "    for classValue, probability in probs.items():\n",
    "        if bestLabel is None or probability>bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreds(summaries, testSet):\n",
    "    preds = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        preds.append(result)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, preds):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == preds[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet)))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ratio = 0.67\n",
    "    filename = \"datasets/5.csv\"\n",
    "    dataset = loadCsv(filename)\n",
    "    trainingSet, testSet = split(dataset, ratio)\n",
    "    print('Train Size', len(trainingSet), 'Test Size', len(testSet))\n",
    "    summaries = summByClass(trainingSet)\n",
    "    preds = getPreds(summaries, testSet)\n",
    "    acc = getAccuracy(testSet, preds)\n",
    "    print('Accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size 514 Test Size 254\n",
      "Accuracy:  55.118110236220474\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
